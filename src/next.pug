.row.mt-4.mb-4
  h2 #[span.emoji ðŸ”®] Next Talks

.row.project
  .col-md-2.col-3
    h3.mb-0 8th
    h5.month.mb-0 November
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Junhyung Park]
    h4.title.mb-1
      | Causal Spaces A measure-theoretic axiomatisation of causality
    .btn-group.btn-group-sm(role="group",aria-label="Commands").mt-1
      
      button.btn.btn-primary(type="button",data-bs-toggle="collapse",data-bs-target="#talk-94ec16d11c0b9c8de0fad620176ed030",aria-expanded="false",aria-controls="talk-94ec16d11c0b9c8de0fad620176ed030")
        | #[i.bi.bi-card-text] Abstract
      a(href="slides/Causal Spaces A measure-theoretic axiomatisation of causality.pdf",target="_blank").btn.btn-primary
        | #[i.bi.bi-file-earmark-text-fill] Paper
  .col-md-7
    p.abstract#talk-94ec16d11c0b9c8de0fad620176ed030.collapse.mt-2
        | We view causality both as an extension of probability theory and as a study of what happens when one intervenes on a system, and argue in favour of taking Kolmogorov's measure-theoretic axiomatisation of probability as the starting point towards an axiomatisation of causality. To that end, we propose the notion of a causal space, consisting of a probability space along with a collection of transition probability kernels, called causal kernels, that encode the causal information of the space. Our proposed framework is not only rigorously grounded in measure theory, but it also sheds light on long-standing limitations of existing frameworks including, for example, cycles, latent variables and stochastic processes.
.row.project
  .col-md-2.col-3
    h3.mb-0 15th
    h5.month.mb-0 November
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Alexander Reisach]
    h4.title.mb-1
      | Sortability in Additive Noise Models
    .btn-group.btn-group-sm(role="group",aria-label="Commands").mt-1
      
      button.btn.btn-primary(type="button",data-bs-toggle="collapse",data-bs-target="#talk-5d315bd4dfe6826ee76219cbfcb279c9",aria-expanded="false",aria-controls="talk-5d315bd4dfe6826ee76219cbfcb279c9")
        | #[i.bi.bi-card-text] Abstract
      a(href="slides/Sortability in Additive Noise Models.pdf",target="_blank").btn.btn-primary
        | #[i.bi.bi-file-earmark-text-fill] Paper
  .col-md-7
    p.abstract#talk-5d315bd4dfe6826ee76219cbfcb279c9.collapse.mt-2
        | Causal graphical models encode causal relationships between variables, typically based on a directed acyclic graph (DAG). Structural causal models expand upon this by expressing the causal relationships as explicit functions, which allows for computing the effect of interventions and much more. We show that, in many common parameterizations using linear functions and additive noise, effects accumulate along the causal order. This property enables inferring the causal order from data simply by sorting by a suitable criterion. We introduce the concept of sortability to capture the magnitude of the phenomenon, and show that the accumulating effects can lead to unrealistic values and deterministic relationships. We discuss implications for existing results and future research based on the same model class.
.row.project
  .col-md-2.col-3
    h3.mb-0 22nd
    h5.month.mb-0 November
    p  when can we assign names to machine representations
  .col-md-7.col-9
    p.author #[span.me Emanuale Marconato]
    h4.title.mb-1
      | A Causal framework for interpreting model representations
    .btn-group.btn-group-sm(role="group",aria-label="Commands").mt-1
      
      button.btn.btn-primary(type="button",data-bs-toggle="collapse",data-bs-target="#talk-6067ba3aca8715ebb6027fd3b65fcf79",aria-expanded="false",aria-controls="talk-6067ba3aca8715ebb6027fd3b65fcf79")
        | #[i.bi.bi-card-text] Abstract
  .col-md-7
    p.abstract#talk-6067ba3aca8715ebb6027fd3b65fcf79.collapse.mt-2
        | There is a growing interest in providing explanations of machine learning models using human-understandable concepts. This integration of concepts can alleviate model opacity due to neural networks opening new venues to design interpretable and trustworthy models. However
.row.project
  .col-md-2.col-3
    h3.mb-0 29th
    h5.month.mb-0 November
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Francesco Montagna]
    h4.title.mb-1
      | Lessons on the identifiability of causal models: classical and supervised learning approaches
    .btn-group.btn-group-sm(role="group",aria-label="Commands").mt-1
      
      button.btn.btn-primary(type="button",data-bs-toggle="collapse",data-bs-target="#talk-38b6a72288fb1459d9b6835855d6ba61",aria-expanded="false",aria-controls="talk-38b6a72288fb1459d9b6835855d6ba61")
        | #[i.bi.bi-card-text] Abstract
  .col-md-7
    p.abstract#talk-38b6a72288fb1459d9b6835855d6ba61.collapse.mt-2
        | Causal discovery from observational data is hindered by restrictive modelling hypotheses that may be unrealistic and hard to verify. In this talk, we will illustrate how score matching estimation enables causal discovery with observational data on broad classes of causal models, with linear and nonlinear mechanisms, even in the presence of latent confounders. We draw the connection between our findings and the general principles that underlie most of the known results on the identifiability of causal models from observational data. Then, we turn our attention to supervised learning-based approaches for causal discovery: a plethora of learning algorithms for the amortized inference of causal graphs have been recently proposed, accompanied by impressive empirical results. Yet, it is unclear when the output of these methods can be trusted, as they do not come with clear identifiability guarantees. We show that amortized causal discovery still needs to obey identifiability theory, but it also differs from classical methods in how the assumptions are formulated, trading more reliance on assumptions on the noise type for fewer hypotheses on the mechanisms.